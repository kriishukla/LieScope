{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11384243,"sourceType":"datasetVersion","datasetId":6933736}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:34:59.469872Z","iopub.execute_input":"2025-04-13T16:34:59.470158Z","iopub.status.idle":"2025-04-13T16:35:04.026073Z","shell.execute_reply.started":"2025-04-13T16:34:59.470128Z","shell.execute_reply":"2025-04-13T16:35:04.024947Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\nimport joblib\n\n\nimport gensim.downloader as api\nfrom tqdm import tqdm\nimport re\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:35:04.027331Z","iopub.execute_input":"2025-04-13T16:35:04.027685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diplomacy/train_df.csv')\n\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/diplomacy/train_df.csv\")\nval_df = pd.read_csv(\"/kaggle/input/diplomacy/val_df.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/diplomacy/test_df.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_text = train_df['messages'].fillna(\"\")\ny_train = train_df['sender_labels'].astype(int)\n\nX_val_text = val_df['messages'].fillna(\"\")\ny_val = val_df['sender_labels'].astype(int)\n\nX_test_text = test_df['messages'].fillna(\"\")\ny_test = test_df['sender_labels'].astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"glove = api.load('glove-wiki-gigaword-100')\n\ndef tokenize(text):\n    return re.findall(r'\\b\\w+\\b', text.lower())\n\ndef get_glove_embedding(text):\n    tokens = tokenize(text)\n    vectors = [glove[word] for word in tokens if word in glove]\n    if vectors:\n        return np.mean(vectors, axis=0)\n    else:\n        return np.zeros(glove.vector_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = np.array([get_glove_embedding(msg) for msg in tqdm(X_train_text)])\nX_val = np.array([get_glove_embedding(msg) for msg in tqdm(X_val_text)])\nX_test = np.array([get_glove_embedding(msg) for msg in tqdm(X_test_text)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save(\"glove_X_train.npy\", X_train)\nnp.save(\"glove_X_val.npy\", X_val)\nnp.save(\"glove_X_test.npy\", X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logreg = LogisticRegression(max_iter=1000)\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_val)\nprint(\"ðŸ”¹ Logistic Regression:\")\nprint(classification_report(y_val, y_pred, digits=3))\n\njoblib.dump(logreg, \"logreg_model.joblib\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:52:23.771205Z","iopub.execute_input":"2025-04-13T16:52:23.771542Z","iopub.status.idle":"2025-04-13T16:52:23.885435Z","shell.execute_reply.started":"2025-04-13T16:52:23.771510Z","shell.execute_reply":"2025-04-13T16:52:23.884597Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¹ Logistic Regression:\n              precision    recall  f1-score   support\n\n           0      0.000     0.000     0.000        99\n           1      0.943     0.999     0.970      1630\n\n    accuracy                          0.942      1729\n   macro avg      0.471     0.500     0.485      1729\nweighted avg      0.889     0.942     0.915      1729\n\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['logreg_model.joblib']"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_val)\nprint(\"ðŸ”¹ Random Forest:\")\nprint(classification_report(y_val, y_pred, digits=3))\n\n# Save\njoblib.dump(rf, \"rf_model.joblib\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:52:24.515939Z","iopub.execute_input":"2025-04-13T16:52:24.516249Z","iopub.status.idle":"2025-04-13T16:52:36.326049Z","shell.execute_reply.started":"2025-04-13T16:52:24.516223Z","shell.execute_reply":"2025-04-13T16:52:36.325150Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¹ Random Forest:\n              precision    recall  f1-score   support\n\n           0      0.500     0.020     0.039        99\n           1      0.944     0.999     0.970      1630\n\n    accuracy                          0.943      1729\n   macro avg      0.722     0.509     0.505      1729\nweighted avg      0.918     0.943     0.917      1729\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['rf_model.joblib']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"svm = SVC(kernel='linear', probability=True)\nsvm.fit(X_train, y_train)\n\ny_pred = svm.predict(X_val)\nprint(\"ðŸ”¹ SVM:\")\nprint(classification_report(y_val, y_pred, digits=3))\n\njoblib.dump(svm, \"svm_model.joblib\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:52:36.327038Z","iopub.execute_input":"2025-04-13T16:52:36.327308Z","iopub.status.idle":"2025-04-13T16:52:42.955864Z","shell.execute_reply.started":"2025-04-13T16:52:36.327287Z","shell.execute_reply":"2025-04-13T16:52:42.954837Z"}},"outputs":[{"name":"stdout","text":"ðŸ”¹ SVM:\n              precision    recall  f1-score   support\n\n           0      0.000     0.000     0.000        99\n           1      0.943     1.000     0.971      1630\n\n    accuracy                          0.943      1729\n   macro avg      0.471     0.500     0.485      1729\nweighted avg      0.889     0.943     0.915      1729\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['svm_model.joblib']"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\nX_train_torch = torch.tensor(X_train, dtype=torch.float32).to(device)\ny_train_torch = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\ntrain_loader = DataLoader(TensorDataset(X_train_torch, y_train_torch), batch_size=64, shuffle=True)\n\nX_val_torch = torch.tensor(X_val, dtype=torch.float32).to(device)\ny_val_torch = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1).to(device)\n\nmlp_torch = MLP(X_train.shape[1]).to(device)\noptimizer = optim.Adam(mlp_torch.parameters(), lr=1e-3)\ncriterion = nn.BCELoss()\n\nfor epoch in range(10):\n    mlp_torch.train()\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = mlp_torch(xb)\n        loss = criterion(preds, yb)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n\n\nmlp_torch.eval()\nwith torch.no_grad():\n    preds = (mlp_torch(X_val_torch) > 0.5).int().cpu().numpy()\n    print(\"ðŸ”¹ MLP (PyTorch):\")\n    print(classification_report(y_val, preds, digits=3))\n\ntorch.save(mlp_torch.state_dict(), \"mlp_torch_model.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T16:52:42.957120Z","iopub.execute_input":"2025-04-13T16:52:42.957340Z","iopub.status.idle":"2025-04-13T16:52:46.624056Z","shell.execute_reply.started":"2025-04-13T16:52:42.957321Z","shell.execute_reply":"2025-04-13T16:52:46.623193Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Loss = 0.0678\nEpoch 2: Loss = 0.0529\nEpoch 3: Loss = 0.5440\nEpoch 4: Loss = 0.0546\nEpoch 5: Loss = 0.0357\nEpoch 6: Loss = 0.0691\nEpoch 7: Loss = 0.0664\nEpoch 8: Loss = 0.0341\nEpoch 9: Loss = 0.0346\nEpoch 10: Loss = 0.0449\nðŸ”¹ MLP (PyTorch):\n              precision    recall  f1-score   support\n\n           0      0.000     0.000     0.000        99\n           1      0.943     1.000     0.971      1630\n\n    accuracy                          0.943      1729\n   macro avg      0.471     0.500     0.485      1729\nweighted avg      0.889     0.943     0.915      1729\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":18}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:18.913769Z",
     "iopub.status.busy": "2025-03-22T04:18:18.913565Z",
     "iopub.status.idle": "2025-03-22T04:18:18.987154Z",
     "shell.execute_reply": "2025-03-22T04:18:18.986209Z",
     "shell.execute_reply.started": "2025-03-22T04:18:18.913751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from io import open\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install sentencepiece\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/input/diplomacy/train.jsonl\"\n",
    "train_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        train_data[i] = json.loads(line)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:18.988158Z",
     "iopub.status.busy": "2025-03-22T04:18:18.987960Z",
     "iopub.status.idle": "2025-03-22T04:18:19.018197Z",
     "shell.execute_reply": "2025-03-22T04:18:19.017466Z",
     "shell.execute_reply.started": "2025-03-22T04:18:18.988141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/input/diplomacy/test.jsonl\"\n",
    "test_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        # Parse the line as JSON\n",
    "        test_data[i] = json.loads(line)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:19.019098Z",
     "iopub.status.busy": "2025-03-22T04:18:19.018817Z",
     "iopub.status.idle": "2025-03-22T04:18:19.022483Z",
     "shell.execute_reply": "2025-03-22T04:18:19.021899Z",
     "shell.execute_reply.started": "2025-03-22T04:18:19.019066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "messages_26= train_data[36][\"messages\"]\n",
    "sender_26= train_data[36][\"sender_labels\"]\n",
    "receiever_26= train_data[36][\"receiver_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:19.024134Z",
     "iopub.status.busy": "2025-03-22T04:18:19.023906Z",
     "iopub.status.idle": "2025-03-22T04:18:19.042069Z",
     "shell.execute_reply": "2025-03-22T04:18:19.041221Z",
     "shell.execute_reply.started": "2025-03-22T04:18:19.024115Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(messages_26), len(sender_26), len(receiever_26))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:19.043604Z",
     "iopub.status.busy": "2025-03-22T04:18:19.043336Z",
     "iopub.status.idle": "2025-03-22T04:18:19.064977Z",
     "shell.execute_reply": "2025-03-22T04:18:19.064273Z",
     "shell.execute_reply.started": "2025-03-22T04:18:19.043584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Russia. Have you worked out what you‚Äôre doing with turkey and Austria yet? I‚Äôm thinking of going anti Germany but want to see how we align in the north first. False NOANNOTATION\n",
      "I sent Turkey a message but still waiting on a reply. I wanted to go anti-Germany too if you want to split the population centers? But if I don‚Äôt hear back from Turkey I may have to fortify my South flank and enter the Balkan‚Äôs even though I don‚Äôt want to. True NOANNOTATION\n",
      "I moving to pressureGermany but I could use assistance on your end. Willing to share any gains that could result. True True\n",
      "Yikes. You have some Turkish trouble. I‚Äôll plan on moving into helgoland bight True NOANNOTATION\n",
      "Yea, that‚Äôs always annoying playing as Russia. Trying to get AH to help out but I have to move one of my troops back West away from pressuring Germany. Oh well. True True\n",
      "That‚Äôs a shame. Let‚Äôs reassess after you handle your problems in the east. True NOANNOTATION\n",
      "Hey man. Let me know if you wanna support my fleet moving to Sweden. Would pressure Germany and keep me a,Ive with a new supply center in my fight in the sky th with Turkey. I‚Äôm gonna need all the help I can get there but have AH help to keep me alive down there. True True\n",
      "Yes, Turkey has been a real thorn in your side. I‚Äôd like to see some pressure on Germany to ease off my unit in Belgium. If I support you into Sweden, will you support me into Denmark? True True\n",
      "Definitely. True NOANNOTATION\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for message in messages_26:\n",
    "    print(message, sender_26[i], receiever_26[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:25.560003Z",
     "iopub.status.busy": "2025-03-22T04:18:25.559700Z",
     "iopub.status.idle": "2025-03-22T04:18:25.624128Z",
     "shell.execute_reply": "2025-03-22T04:18:25.623398Z",
     "shell.execute_reply.started": "2025-03-22T04:18:25.559979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs, targets = [], []\n",
    "\n",
    "for key, instance in train_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        inputs.append(f\"context: {context} classify: {message}\")\n",
    "        targets.append(\"true\" if label else \"false\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:25.625159Z",
     "iopub.status.busy": "2025-03-22T04:18:25.624931Z",
     "iopub.status.idle": "2025-03-22T04:18:25.630512Z",
     "shell.execute_reply": "2025-03-22T04:18:25.629918Z",
     "shell.execute_reply.started": "2025-03-22T04:18:25.625139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13132 13132\n",
      "context: Germany!\n",
      "\n",
      "Just the person I want to speak with. I have a somewhat crazy idea that I‚Äôve always wanted to try with I/G, but I‚Äôve never actually convinced the other guy to try it. And, what‚Äôs worse, it might make you suspicious of me. \n",
      "\n",
      "So...do I suggest it?\n",
      "\n",
      "I‚Äôm thinking that this is a low stakes game, not a tournament or anything, and an interesting and unusual move set might make it more fun? That‚Äôs my hope anyway.\n",
      "\n",
      "What is your appetite like for unusual and crazy? You've whet my appetite, Italy. What's the suggestion? üëç classify: It seems like there are a lot of ways that could go wrong...I don't see why France would see you approaching/taking Munich--while I do nothing about it--and not immediately feel skittish\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs), len(targets)) \n",
    "print(inputs[3])\n",
    "print(targets[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:25.631542Z",
     "iopub.status.busy": "2025-03-22T04:18:25.631319Z",
     "iopub.status.idle": "2025-03-22T04:18:25.661341Z",
     "shell.execute_reply": "2025-03-22T04:18:25.660491Z",
     "shell.execute_reply.started": "2025-03-22T04:18:25.631514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_inputs, test_targets = [], []\n",
    "\n",
    "for key, instance in test_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        test_inputs.append(f\"context: {context} classify: {message}\")\n",
    "        test_targets.append(\"true\" if label else \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:29.114200Z",
     "iopub.status.busy": "2025-03-22T04:18:29.113891Z",
     "iopub.status.idle": "2025-03-22T04:18:35.197744Z",
     "shell.execute_reply": "2025-03-22T04:18:35.196710Z",
     "shell.execute_reply.started": "2025-03-22T04:18:29.114166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DiplomacyDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "        assert len(self.encodings['input_ids']) == len(self.labels['input_ids']), \"Encodings and labels must have the same number of samples.\"\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:38.721187Z",
     "iopub.status.busy": "2025-03-22T04:18:38.720953Z",
     "iopub.status.idle": "2025-03-22T04:18:38.743970Z",
     "shell.execute_reply": "2025-03-22T04:18:38.743336Z",
     "shell.execute_reply.started": "2025-03-22T04:18:38.721165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/input/diplomacy/validation.jsonl\"\n",
    "validation_data = {}\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        validation_data[i] = json.loads(line)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:18:38.745015Z",
     "iopub.status.busy": "2025-03-22T04:18:38.744759Z",
     "iopub.status.idle": "2025-03-22T04:18:38.756259Z",
     "shell.execute_reply": "2025-03-22T04:18:38.755321Z",
     "shell.execute_reply.started": "2025-03-22T04:18:38.744994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_texts, targetval_texts = [], []\n",
    "\n",
    "for key, instance in validation_data.items():\n",
    "    if isinstance(instance, dict) and 'messages' in instance:\n",
    "        messages = instance['messages']\n",
    "        sender_labels = instance['sender_labels']\n",
    "\n",
    "    for idx, (message, label) in enumerate(zip(messages, sender_labels)):\n",
    "        start_index = max(0, idx-10)\n",
    "        end_index = min(len(messages)-1, idx)\n",
    "        context = \" \".join(messages[start_index:end_index])\n",
    "        val_texts.append(f\"context: {context} classify: {message}\")\n",
    "        targetval_texts.append(\"true\" if label else \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:19:06.398784Z",
     "iopub.status.busy": "2025-03-22T04:19:06.398340Z",
     "iopub.status.idle": "2025-03-22T04:19:17.207598Z",
     "shell.execute_reply": "2025-03-22T04:19:17.206664Z",
     "shell.execute_reply.started": "2025-03-22T04:19:06.398763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bd0d0dd1ef4428bbce67c28f4e4a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5605f99bfe04222afed5a353787e777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2c41534ee64733849d96484ab479b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd0af142bdc4460887dee707db692d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218a0a243deb429aaf55a1f0927c36e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "val_encodings = tokenizer(val_texts, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:19:17.209006Z",
     "iopub.status.busy": "2025-03-22T04:19:17.208636Z",
     "iopub.status.idle": "2025-03-22T04:27:25.503274Z",
     "shell.execute_reply": "2025-03-22T04:27:25.502243Z",
     "shell.execute_reply.started": "2025-03-22T04:19:17.208972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13132\n"
     ]
    }
   ],
   "source": [
    "x_embeddings = []\n",
    "\n",
    "print(len(inputs))\n",
    "for text in inputs:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Move the model to the correct device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Tokenize the input text and move the tokens to the same device as the model\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "    tokens = {key: value.to(device) for key, value in tokens.items()}\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Access the embeddings\n",
    "    x_embeddings.append(outputs.pooler_output.squeeze().cpu().numpy())  \n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, k_neighbors=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:27:25.504485Z",
     "iopub.status.busy": "2025-03-22T04:27:25.504226Z",
     "iopub.status.idle": "2025-03-22T04:27:35.678033Z",
     "shell.execute_reply": "2025-03-22T04:27:35.677040Z",
     "shell.execute_reply.started": "2025-03-22T04:27:25.504463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = np.stack(x_embeddings)\n",
    "Y = np.array(targets)  \n",
    "X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_resampled)\n",
    "clf = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "\n",
    "clf.fit(X_resampled, Y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:27:35.679397Z",
     "iopub.status.busy": "2025-03-22T04:27:35.679061Z",
     "iopub.status.idle": "2025-03-22T04:27:35.684101Z",
     "shell.execute_reply": "2025-03-22T04:27:35.683430Z",
     "shell.execute_reply.started": "2025-03-22T04:27:35.679368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (18811, 768)\n",
      "Shape of Y: (18811,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X_resampled.shape)\n",
    "print(\"Shape of Y:\", Y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:27:35.685021Z",
     "iopub.status.busy": "2025-03-22T04:27:35.684762Z",
     "iopub.status.idle": "2025-03-22T04:29:15.544691Z",
     "shell.execute_reply": "2025-03-22T04:29:15.543912Z",
     "shell.execute_reply.started": "2025-03-22T04:27:35.684989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move model to the correct device (either 'cuda' or 'cpu')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "x_test_embeddings = []\n",
    "\n",
    "print(len(test_inputs))\n",
    "\n",
    "for text in test_inputs:\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "    \n",
    "    # Move the tokenized inputs to the same device as the model\n",
    "    tokens = {key: value.to(device) for key, value in tokens.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Perform the forward pass\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Extract the embeddings (pooler_output) and append to the list\n",
    "    x_test_embeddings.append(outputs.pooler_output.squeeze().cpu().numpy())  # Move output back to CPU if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:29:15.545618Z",
     "iopub.status.busy": "2025-03-22T04:29:15.545416Z",
     "iopub.status.idle": "2025-03-22T04:29:15.579063Z",
     "shell.execute_reply": "2025-03-22T04:29:15.578097Z",
     "shell.execute_reply.started": "2025-03-22T04:29:15.545601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7533746807734404\n"
     ]
    }
   ],
   "source": [
    "X_test = np.stack(x_test_embeddings)\n",
    "Y_test = np.array(test_targets)  \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:29:15.580730Z",
     "iopub.status.busy": "2025-03-22T04:29:15.580119Z",
     "iopub.status.idle": "2025-03-22T04:29:15.630933Z",
     "shell.execute_reply": "2025-03-22T04:29:15.629742Z",
     "shell.execute_reply.started": "2025-03-22T04:29:15.580493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.14      0.34      0.19       240\n",
      "        true       0.93      0.79      0.85      2501\n",
      "\n",
      "    accuracy                           0.75      2741\n",
      "   macro avg       0.53      0.57      0.52      2741\n",
      "weighted avg       0.86      0.75      0.80      2741\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  81  159]\n",
      " [ 517 1984]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:39:39.018406Z",
     "iopub.status.busy": "2025-03-22T04:39:39.018075Z",
     "iopub.status.idle": "2025-03-22T04:39:39.024498Z",
     "shell.execute_reply": "2025-03-22T04:39:39.023539Z",
     "shell.execute_reply.started": "2025-03-22T04:39:39.018383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(clf, 'logistic_regression_model.pkl')\n",
    "\n",
    "model.save_pretrained('bert_model')\n",
    "tokenizer.save_pretrained('bert_model')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6933736,
     "sourceId": 11119423,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11384243,"sourceType":"datasetVersion","datasetId":6933736}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom tqdm import tqdm\nimport os\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:58:59.263762Z","iopub.execute_input":"2025-04-13T06:58:59.264091Z","iopub.status.idle":"2025-04-13T06:59:21.199803Z","shell.execute_reply.started":"2025-04-13T06:58:59.264065Z","shell.execute_reply":"2025-04-13T06:59:21.199131Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diplomacy/train_df.csv')\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:21.200777Z","iopub.execute_input":"2025-04-13T06:59:21.201388Z","iopub.status.idle":"2025-04-13T06:59:21.327790Z","shell.execute_reply.started":"2025-04-13T06:59:21.201349Z","shell.execute_reply":"2025-04-13T06:59:21.326963Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                            messages  sender_labels  \\\n0                    Tsk tsk, I told you I was right          False   \n1  Yeah, something tells me that player may be a ...           True   \n2       Regardless of which way it falls in the end.           True   \n3  Austria is going to hedgehog though so I doubt...          False   \n4                                I talked to Austria           True   \n\n  receiver_labels speakers receivers  absolute_message_index  \\\n0    NOANNOTATION   france   germany                     492   \n1            True  england    france                      63   \n2            True  england   germany                    1477   \n3            True    italy    russia                     133   \n4            True  germany   england                    1363   \n\n   relative_message_index seasons  years  game_score  game_score_delta  \\\n0                     117  Winter   1909           7                 4   \n1                       8  Spring   1901           3                 0   \n2                     279  Spring   1906           5                 0   \n3                       9  Spring   1901           3                -1   \n4                      94    Fall   1902           5                 0   \n\n           players  game_id  politeness  negative_sentiment  \\\n0   germany,france        6    3.185824                 0.0   \n1   england,france        1    3.535946                 0.0   \n2  germany,england        1    3.207375                 0.0   \n3     italy,russia        7    3.171482                 0.0   \n4  germany,england        2    3.239397                 0.0   \n\n   neutral_sentiment  positive_sentiment  vader_score  \n0                1.0                 0.0       0.0000  \n1                0.8                 0.2       0.9260  \n2                1.0                 0.0       0.0000  \n3                1.0                 0.0      -0.5009  \n4                1.0                 0.0       0.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>messages</th>\n      <th>sender_labels</th>\n      <th>receiver_labels</th>\n      <th>speakers</th>\n      <th>receivers</th>\n      <th>absolute_message_index</th>\n      <th>relative_message_index</th>\n      <th>seasons</th>\n      <th>years</th>\n      <th>game_score</th>\n      <th>game_score_delta</th>\n      <th>players</th>\n      <th>game_id</th>\n      <th>politeness</th>\n      <th>negative_sentiment</th>\n      <th>neutral_sentiment</th>\n      <th>positive_sentiment</th>\n      <th>vader_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tsk tsk, I told you I was right</td>\n      <td>False</td>\n      <td>NOANNOTATION</td>\n      <td>france</td>\n      <td>germany</td>\n      <td>492</td>\n      <td>117</td>\n      <td>Winter</td>\n      <td>1909</td>\n      <td>7</td>\n      <td>4</td>\n      <td>germany,france</td>\n      <td>6</td>\n      <td>3.185824</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yeah, something tells me that player may be a ...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>england</td>\n      <td>france</td>\n      <td>63</td>\n      <td>8</td>\n      <td>Spring</td>\n      <td>1901</td>\n      <td>3</td>\n      <td>0</td>\n      <td>england,france</td>\n      <td>1</td>\n      <td>3.535946</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>0.2</td>\n      <td>0.9260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Regardless of which way it falls in the end.</td>\n      <td>True</td>\n      <td>True</td>\n      <td>england</td>\n      <td>germany</td>\n      <td>1477</td>\n      <td>279</td>\n      <td>Spring</td>\n      <td>1906</td>\n      <td>5</td>\n      <td>0</td>\n      <td>germany,england</td>\n      <td>1</td>\n      <td>3.207375</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Austria is going to hedgehog though so I doubt...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>italy</td>\n      <td>russia</td>\n      <td>133</td>\n      <td>9</td>\n      <td>Spring</td>\n      <td>1901</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>italy,russia</td>\n      <td>7</td>\n      <td>3.171482</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.5009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I talked to Austria</td>\n      <td>True</td>\n      <td>True</td>\n      <td>germany</td>\n      <td>england</td>\n      <td>1363</td>\n      <td>94</td>\n      <td>Fall</td>\n      <td>1902</td>\n      <td>5</td>\n      <td>0</td>\n      <td>germany,england</td>\n      <td>2</td>\n      <td>3.239397</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:21.329646Z","iopub.execute_input":"2025-04-13T06:59:21.329912Z","iopub.status.idle":"2025-04-13T06:59:21.405297Z","shell.execute_reply.started":"2025-04-13T06:59:21.329890Z","shell.execute_reply":"2025-04-13T06:59:21.404370Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/diplomacy/train_df.csv\")\nval_df = pd.read_csv(\"/kaggle/input/diplomacy/val_df.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/diplomacy/test_df.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:21.406754Z","iopub.execute_input":"2025-04-13T06:59:21.407106Z","iopub.status.idle":"2025-04-13T06:59:21.530307Z","shell.execute_reply.started":"2025-04-13T06:59:21.407070Z","shell.execute_reply":"2025-04-13T06:59:21.529600Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nx_train = train_df[\"messages\"].tolist()\ny_train = train_df[\"sender_labels\"].astype(int).tolist()\n\nx_val = val_df[\"messages\"].tolist()\ny_val = val_df[\"sender_labels\"].astype(int).tolist()\n\nx_test = test_df[\"messages\"].tolist()\ny_test = test_df[\"sender_labels\"].astype(int).tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:21.531047Z","iopub.execute_input":"2025-04-13T06:59:21.531286Z","iopub.status.idle":"2025-04-13T06:59:21.537354Z","shell.execute_reply.started":"2025-04-13T06:59:21.531266Z","shell.execute_reply":"2025-04-13T06:59:21.536572Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nbert_model.to(device)\nbert_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:21.538258Z","iopub.execute_input":"2025-04-13T06:59:21.538584Z","iopub.status.idle":"2025-04-13T06:59:25.336538Z","shell.execute_reply.started":"2025-04-13T06:59:21.538550Z","shell.execute_reply":"2025-04-13T06:59:25.335704Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87902b0773e449bf98f57e8ee762577b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d965bddda2457f8dc9be61bae99bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6366bf4616743b5adb150e0d7e948a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df85f642f87148918738310b19a7c601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46841a070d3b4b2b989c05f438fdd95c"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def get_bert_embeddings(texts, tokenizer, model, max_len=128):\n    embeddings = []\n    for text in tqdm(texts):\n        tokens = tokenizer(text, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n        tokens = {k: v.to(device) for k, v in tokens.items()}\n        with torch.no_grad():\n            output = model(**tokens)\n        cls_embedding = output.last_hidden_state[:, 0, :]  # [CLS] token\n        embeddings.append(cls_embedding.squeeze().cpu().numpy())\n    return torch.tensor(embeddings).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:25.337445Z","iopub.execute_input":"2025-04-13T06:59:25.337763Z","iopub.status.idle":"2025-04-13T06:59:25.342640Z","shell.execute_reply.started":"2025-04-13T06:59:25.337731Z","shell.execute_reply":"2025-04-13T06:59:25.341861Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"x_train_vec = get_bert_embeddings(x_train, tokenizer, bert_model)\nx_val_vec = get_bert_embeddings(x_val, tokenizer, bert_model)\nx_test_vec = get_bert_embeddings(x_test, tokenizer, bert_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:59:25.345090Z","iopub.execute_input":"2025-04-13T06:59:25.345313Z","iopub.status.idle":"2025-04-13T07:02:24.296800Z","shell.execute_reply.started":"2025-04-13T06:59:25.345294Z","shell.execute_reply":"2025-04-13T07:02:24.295904Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 12102/12102 [02:02<00:00, 98.63it/s]\n<ipython-input-7-0fe0b6076746>:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  return torch.tensor(embeddings).numpy()\n100%|██████████| 1729/1729 [00:17<00:00, 96.09it/s]\n100%|██████████| 3458/3458 [00:36<00:00, 95.64it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"clf = LogisticRegression(max_iter=1000)\nclf.fit(x_train_vec, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:02:24.298296Z","iopub.execute_input":"2025-04-13T07:02:24.298642Z","iopub.status.idle":"2025-04-13T07:02:29.177658Z","shell.execute_reply.started":"2025-04-13T07:02:24.298609Z","shell.execute_reply":"2025-04-13T07:02:29.176763Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(\"saved_models\", exist_ok=True)\njoblib.dump(clf, \"saved_models/logistic_regression_bert.joblib\")\njoblib.dump((x_train_vec, y_train), \"saved_models/train_embeddings.joblib\")\njoblib.dump((x_val_vec, y_val), \"saved_models/val_embeddings.joblib\")\njoblib.dump((x_test_vec, y_test), \"saved_models/test_embeddings.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:02:29.178493Z","iopub.execute_input":"2025-04-13T07:02:29.178817Z","iopub.status.idle":"2025-04-13T07:02:29.286772Z","shell.execute_reply.started":"2025-04-13T07:02:29.178793Z","shell.execute_reply":"2025-04-13T07:02:29.286108Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['saved_models/test_embeddings.joblib']"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"val_preds = clf.predict(x_val_vec)\ntest_preds = clf.predict(x_test_vec)\n\nprint(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\nprint(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, test_preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear', probability=True)\nsvm.fit(x_train_vec, y_train)\n\n# Save model\njoblib.dump(svm, \"saved_models/svm_bert.joblib\")\n\n# Evaluate\nprint(\"SVM Test Accuracy:\", accuracy_score(y_test, svm.predict(x_test_vec)))\nprint(\"SVM Report:\\n\", classification_report(y_test, svm.predict(x_test_vec)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:02:29.287606Z","iopub.execute_input":"2025-04-13T07:02:29.287895Z","iopub.status.idle":"2025-04-13T07:05:15.317600Z","shell.execute_reply.started":"2025-04-13T07:02:29.287868Z","shell.execute_reply":"2025-04-13T07:05:15.316747Z"}},"outputs":[{"name":"stdout","text":"SVM Test Accuracy: 0.9531521110468479\nSVM Report:\n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       162\n           1       0.95      1.00      0.98      3296\n\n    accuracy                           0.95      3458\n   macro avg       0.48      0.50      0.49      3458\nweighted avg       0.91      0.95      0.93      3458\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Prepare DataLoader\ntrain_dataset = TensorDataset(torch.tensor(x_train_vec).float(), torch.tensor(y_train).long())\nval_dataset = TensorDataset(torch.tensor(x_val_vec).float(), torch.tensor(y_val).long())\ntest_dataset = TensorDataset(torch.tensor(x_test_vec).float(), torch.tensor(y_test).long())\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\n# Simple NN Model\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim=768, hidden_dim=256, num_classes=2):\n        super(SimpleNN, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, num_classes)\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nmodel = SimpleNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        out = model(xb)\n        loss = criterion(out, yb)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1} - Train Loss: {total_loss/len(train_loader):.4f}\")\n\n# Evaluation on test\nmodel.eval()\ncorrect, total = 0, 0\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for xb, yb in test_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        out = model(xb)\n        preds = out.argmax(dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(yb.cpu().numpy())\n        correct += (preds == yb).sum().item()\n        total += yb.size(0)\n\n# Save model\ntorch.save(model.state_dict(), \"saved_models/simple_nn_bert.pth\")\n\n# Report\nprint(\"NN Test Accuracy:\", correct / total)\nprint(\"NN Report:\\n\", classification_report(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:05:15.318640Z","iopub.execute_input":"2025-04-13T07:05:15.319008Z","iopub.status.idle":"2025-04-13T07:05:19.101161Z","shell.execute_reply.started":"2025-04-13T07:05:15.318971Z","shell.execute_reply":"2025-04-13T07:05:19.100113Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 - Train Loss: 0.2075\nEpoch 2 - Train Loss: 0.2021\nEpoch 3 - Train Loss: 0.1976\nEpoch 4 - Train Loss: 0.1953\nEpoch 5 - Train Loss: 0.1936\nNN Test Accuracy: 0.9531521110468479\nNN Report:\n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       162\n           1       0.95      1.00      0.98      3296\n\n    accuracy                           0.95      3458\n   macro avg       0.48      0.50      0.49      3458\nweighted avg       0.91      0.95      0.93      3458\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(x_train_vec, y_train)\n\n# Save model\njoblib.dump(rf, \"saved_models/random_forest_bert.joblib\")\n\n# Evaluate\nprint(\"RF Test Accuracy:\", accuracy_score(y_test, rf.predict(x_test_vec)))\nprint(\"RF Report:\\n\", classification_report(y_test, rf.predict(x_test_vec)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:05:19.102040Z","iopub.execute_input":"2025-04-13T07:05:19.102294Z","iopub.status.idle":"2025-04-13T07:06:48.108973Z","shell.execute_reply.started":"2025-04-13T07:05:19.102273Z","shell.execute_reply":"2025-04-13T07:06:48.108238Z"}},"outputs":[{"name":"stdout","text":"RF Test Accuracy: 0.9540196645459803\nRF Report:\n               precision    recall  f1-score   support\n\n           0       0.80      0.02      0.05       162\n           1       0.95      1.00      0.98      3296\n\n    accuracy                           0.95      3458\n   macro avg       0.88      0.51      0.51      3458\nweighted avg       0.95      0.95      0.93      3458\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import AutoTokenizer\n\n# # Use BERT base or any variant you prefer\n# model_name = \"bert-base-uncased\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# def tokenize(example):\n#     return tokenizer(example[\"messages\"], truncation=True, padding=\"max_length\", max_length=128)\n\n# train_dataset = train_dataset.map(tokenize, batched=True)\n# val_dataset = val_dataset.map(tokenize, batched=True)\n# test_dataset = test_dataset.map(tokenize, batched=True)\n\n# # Set format for PyTorch\n# train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n# val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n# test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:06:48.109732Z","iopub.execute_input":"2025-04-13T07:06:48.110008Z","iopub.status.idle":"2025-04-13T07:06:48.113387Z","shell.execute_reply.started":"2025-04-13T07:06:48.109975Z","shell.execute_reply":"2025-04-13T07:06:48.112697Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# from sentence_transformers import SentenceTransformer\n\n# model = SentenceTransformer('all-MiniLM-L6-v2')\n# embeddings = model.encode(df['messages'].tolist(), convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:06:48.114208Z","iopub.execute_input":"2025-04-13T07:06:48.114499Z","iopub.status.idle":"2025-04-13T07:06:48.128740Z","shell.execute_reply.started":"2025-04-13T07:06:48.114466Z","shell.execute_reply":"2025-04-13T07:06:48.128130Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModel\n\n# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n# model = AutoModel.from_pretrained(\"roberta-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:06:48.129393Z","iopub.execute_input":"2025-04-13T07:06:48.129578Z","iopub.status.idle":"2025-04-13T07:06:48.139852Z","shell.execute_reply.started":"2025-04-13T07:06:48.129562Z","shell.execute_reply":"2025-04-13T07:06:48.139212Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# import gensim.downloader as api\n\n# model = api.load(\"glove-wiki-gigaword-100\")\n# embedding = model['hello']  # Get word vector\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T07:06:48.140600Z","iopub.execute_input":"2025-04-13T07:06:48.140854Z","iopub.status.idle":"2025-04-13T07:06:48.152651Z","shell.execute_reply.started":"2025-04-13T07:06:48.140819Z","shell.execute_reply":"2025-04-13T07:06:48.152020Z"}},"outputs":[],"execution_count":17}]}
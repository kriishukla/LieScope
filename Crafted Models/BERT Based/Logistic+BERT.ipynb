{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11384243,"sourceType":"datasetVersion","datasetId":6933736}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom tqdm import tqdm\nimport os\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:34:49.487594Z","iopub.execute_input":"2025-04-13T06:34:49.487907Z","iopub.status.idle":"2025-04-13T06:34:49.492108Z","shell.execute_reply.started":"2025-04-13T06:34:49.487881Z","shell.execute_reply":"2025-04-13T06:34:49.491200Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diplomacy/train_df.csv')\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.293731Z","iopub.execute_input":"2025-04-13T06:30:44.293942Z","iopub.status.idle":"2025-04-13T06:30:44.362294Z","shell.execute_reply.started":"2025-04-13T06:30:44.293924Z","shell.execute_reply":"2025-04-13T06:30:44.361604Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                            messages  sender_labels  \\\n0                    Tsk tsk, I told you I was right          False   \n1  Yeah, something tells me that player may be a ...           True   \n2       Regardless of which way it falls in the end.           True   \n3  Austria is going to hedgehog though so I doubt...          False   \n4                                I talked to Austria           True   \n\n  receiver_labels speakers receivers  absolute_message_index  \\\n0    NOANNOTATION   france   germany                     492   \n1            True  england    france                      63   \n2            True  england   germany                    1477   \n3            True    italy    russia                     133   \n4            True  germany   england                    1363   \n\n   relative_message_index seasons  years  game_score  game_score_delta  \\\n0                     117  Winter   1909           7                 4   \n1                       8  Spring   1901           3                 0   \n2                     279  Spring   1906           5                 0   \n3                       9  Spring   1901           3                -1   \n4                      94    Fall   1902           5                 0   \n\n           players  game_id  politeness  negative_sentiment  \\\n0   germany,france        6    3.185824                 0.0   \n1   england,france        1    3.535946                 0.0   \n2  germany,england        1    3.207375                 0.0   \n3     italy,russia        7    3.171482                 0.0   \n4  germany,england        2    3.239397                 0.0   \n\n   neutral_sentiment  positive_sentiment  vader_score  \n0                1.0                 0.0       0.0000  \n1                0.8                 0.2       0.9260  \n2                1.0                 0.0       0.0000  \n3                1.0                 0.0      -0.5009  \n4                1.0                 0.0       0.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>messages</th>\n      <th>sender_labels</th>\n      <th>receiver_labels</th>\n      <th>speakers</th>\n      <th>receivers</th>\n      <th>absolute_message_index</th>\n      <th>relative_message_index</th>\n      <th>seasons</th>\n      <th>years</th>\n      <th>game_score</th>\n      <th>game_score_delta</th>\n      <th>players</th>\n      <th>game_id</th>\n      <th>politeness</th>\n      <th>negative_sentiment</th>\n      <th>neutral_sentiment</th>\n      <th>positive_sentiment</th>\n      <th>vader_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tsk tsk, I told you I was right</td>\n      <td>False</td>\n      <td>NOANNOTATION</td>\n      <td>france</td>\n      <td>germany</td>\n      <td>492</td>\n      <td>117</td>\n      <td>Winter</td>\n      <td>1909</td>\n      <td>7</td>\n      <td>4</td>\n      <td>germany,france</td>\n      <td>6</td>\n      <td>3.185824</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yeah, something tells me that player may be a ...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>england</td>\n      <td>france</td>\n      <td>63</td>\n      <td>8</td>\n      <td>Spring</td>\n      <td>1901</td>\n      <td>3</td>\n      <td>0</td>\n      <td>england,france</td>\n      <td>1</td>\n      <td>3.535946</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>0.2</td>\n      <td>0.9260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Regardless of which way it falls in the end.</td>\n      <td>True</td>\n      <td>True</td>\n      <td>england</td>\n      <td>germany</td>\n      <td>1477</td>\n      <td>279</td>\n      <td>Spring</td>\n      <td>1906</td>\n      <td>5</td>\n      <td>0</td>\n      <td>germany,england</td>\n      <td>1</td>\n      <td>3.207375</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Austria is going to hedgehog though so I doubt...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>italy</td>\n      <td>russia</td>\n      <td>133</td>\n      <td>9</td>\n      <td>Spring</td>\n      <td>1901</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>italy,russia</td>\n      <td>7</td>\n      <td>3.171482</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.5009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I talked to Austria</td>\n      <td>True</td>\n      <td>True</td>\n      <td>germany</td>\n      <td>england</td>\n      <td>1363</td>\n      <td>94</td>\n      <td>Fall</td>\n      <td>1902</td>\n      <td>5</td>\n      <td>0</td>\n      <td>germany,england</td>\n      <td>2</td>\n      <td>3.239397</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.363140Z","iopub.execute_input":"2025-04-13T06:30:44.363358Z","iopub.status.idle":"2025-04-13T06:30:44.367840Z","shell.execute_reply.started":"2025-04-13T06:30:44.363328Z","shell.execute_reply":"2025-04-13T06:30:44.367111Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/diplomacy/train_df.csv\")\nval_df = pd.read_csv(\"/kaggle/input/diplomacy/val_df.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/diplomacy/test_df.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.369148Z","iopub.execute_input":"2025-04-13T06:30:44.369341Z","iopub.status.idle":"2025-04-13T06:30:44.454202Z","shell.execute_reply.started":"2025-04-13T06:30:44.369324Z","shell.execute_reply":"2025-04-13T06:30:44.453337Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\nx_train = train_df[\"messages\"].tolist()\ny_train = train_df[\"sender_labels\"].astype(int).tolist()\n\nx_val = val_df[\"messages\"].tolist()\ny_val = val_df[\"sender_labels\"].astype(int).tolist()\n\nx_test = test_df[\"messages\"].tolist()\ny_test = test_df[\"sender_labels\"].astype(int).tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.455560Z","iopub.execute_input":"2025-04-13T06:30:44.455888Z","iopub.status.idle":"2025-04-13T06:30:44.462057Z","shell.execute_reply.started":"2025-04-13T06:30:44.455855Z","shell.execute_reply":"2025-04-13T06:30:44.461245Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nbert_model.to(device)\nbert_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.462736Z","iopub.execute_input":"2025-04-13T06:30:44.462975Z","iopub.status.idle":"2025-04-13T06:30:44.852452Z","shell.execute_reply.started":"2025-04-13T06:30:44.462956Z","shell.execute_reply":"2025-04-13T06:30:44.851593Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def get_bert_embeddings(texts, tokenizer, model, max_len=128):\n    embeddings = []\n    for text in tqdm(texts):\n        tokens = tokenizer(text, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n        tokens = {k: v.to(device) for k, v in tokens.items()}\n        with torch.no_grad():\n            output = model(**tokens)\n        cls_embedding = output.last_hidden_state[:, 0, :]  # [CLS] token\n        embeddings.append(cls_embedding.squeeze().cpu().numpy())\n    return torch.tensor(embeddings).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.853324Z","iopub.execute_input":"2025-04-13T06:30:44.853621Z","iopub.status.idle":"2025-04-13T06:30:44.858141Z","shell.execute_reply.started":"2025-04-13T06:30:44.853599Z","shell.execute_reply":"2025-04-13T06:30:44.857311Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"x_train_vec = get_bert_embeddings(x_train, tokenizer, bert_model)\nx_val_vec = get_bert_embeddings(x_val, tokenizer, bert_model)\nx_test_vec = get_bert_embeddings(x_test, tokenizer, bert_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:30:44.858934Z","iopub.execute_input":"2025-04-13T06:30:44.859189Z","iopub.status.idle":"2025-04-13T06:33:46.316830Z","shell.execute_reply.started":"2025-04-13T06:30:44.859163Z","shell.execute_reply":"2025-04-13T06:33:46.316044Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 12102/12102 [02:05<00:00, 96.71it/s]\n<ipython-input-25-0fe0b6076746>:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  return torch.tensor(embeddings).numpy()\n100%|██████████| 1729/1729 [00:17<00:00, 96.42it/s]\n100%|██████████| 3458/3458 [00:36<00:00, 94.90it/s]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"clf = LogisticRegression(max_iter=1000)\nclf.fit(x_train_vec, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:46.319032Z","iopub.execute_input":"2025-04-13T06:33:46.319311Z","iopub.status.idle":"2025-04-13T06:33:51.040031Z","shell.execute_reply.started":"2025-04-13T06:33:46.319286Z","shell.execute_reply":"2025-04-13T06:33:51.039145Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"os.makedirs(\"saved_models\", exist_ok=True)\njoblib.dump(clf, \"saved_models/logistic_regression_bert.joblib\")\njoblib.dump((x_train_vec, y_train), \"saved_models/train_embeddings.joblib\")\njoblib.dump((x_val_vec, y_val), \"saved_models/val_embeddings.joblib\")\njoblib.dump((x_test_vec, y_test), \"saved_models/test_embeddings.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:34:55.020030Z","iopub.execute_input":"2025-04-13T06:34:55.020309Z","iopub.status.idle":"2025-04-13T06:34:55.130966Z","shell.execute_reply.started":"2025-04-13T06:34:55.020286Z","shell.execute_reply":"2025-04-13T06:34:55.130223Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['saved_models/test_embeddings.joblib']"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"val_preds = clf.predict(x_val_vec)\ntest_preds = clf.predict(x_test_vec)\n\nprint(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\nprint(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, test_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:35:45.358668Z","iopub.execute_input":"2025-04-13T06:35:45.358978Z","iopub.status.idle":"2025-04-13T06:35:45.389270Z","shell.execute_reply.started":"2025-04-13T06:35:45.358953Z","shell.execute_reply":"2025-04-13T06:35:45.388515Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9421631000578369\nTest Accuracy: 0.9517061885482938\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.38      0.05      0.09       162\n           1       0.96      1.00      0.98      3296\n\n    accuracy                           0.95      3458\n   macro avg       0.67      0.52      0.53      3458\nweighted avg       0.93      0.95      0.93      3458\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import AutoTokenizer\n\n# # Use BERT base or any variant you prefer\n# model_name = \"bert-base-uncased\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# def tokenize(example):\n#     return tokenizer(example[\"messages\"], truncation=True, padding=\"max_length\", max_length=128)\n\n# train_dataset = train_dataset.map(tokenize, batched=True)\n# val_dataset = val_dataset.map(tokenize, batched=True)\n# test_dataset = test_dataset.map(tokenize, batched=True)\n\n# # Set format for PyTorch\n# train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n# val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n# test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'sender_labels'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:51.067361Z","iopub.status.idle":"2025-04-13T06:33:51.067723Z","shell.execute_reply":"2025-04-13T06:33:51.067598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sentence_transformers import SentenceTransformer\n\n# model = SentenceTransformer('all-MiniLM-L6-v2')\n# embeddings = model.encode(df['messages'].tolist(), convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:51.068614Z","iopub.status.idle":"2025-04-13T06:33:51.068952Z","shell.execute_reply":"2025-04-13T06:33:51.068818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:51.069931Z","iopub.status.idle":"2025-04-13T06:33:51.070256Z","shell.execute_reply":"2025-04-13T06:33:51.070143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModel\n\n# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n# model = AutoModel.from_pretrained(\"roberta-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:51.071190Z","iopub.status.idle":"2025-04-13T06:33:51.071568Z","shell.execute_reply":"2025-04-13T06:33:51.071361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import gensim.downloader as api\n\n# model = api.load(\"glove-wiki-gigaword-100\")\n# embedding = model['hello']  # Get word vector\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:33:51.072597Z","iopub.status.idle":"2025-04-13T06:33:51.072899Z","shell.execute_reply":"2025-04-13T06:33:51.072766Z"}},"outputs":[],"execution_count":null}]}